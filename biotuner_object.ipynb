{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from fractions import Fraction\n",
    "import itertools\n",
    "from biotuner_utils import *\n",
    "from biotuner_offline import *\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array, zeros, ones, arange, log2, sqrt, diff, concatenate\n",
    "import emd\n",
    "from PyEMD import EMD, EEMD\n",
    "from scipy.signal import butter, lfilter\n",
    "import colorednoise as cn\n",
    "from biotuner import *\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path = 'D:/Science/EEG_data/'\n",
    "path = 'C:/Users/Dell/GitHub/CoCoBrainChannel/'\n",
    "epochs = mne.read_epochs(path+'pareidolia_run2.fif')\n",
    "#epochs = mne.read_epochs('C:/Users/Antoine/github/Data_EEG/pareidolia_run1.fif')\n",
    "epochs = epochs.apply_baseline((-1.5, -0.1))\n",
    "#epochs = epochs.crop(0.5, 7.5)\n",
    "epochs_data = epochs.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize biotuner object and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biotuner(object):\n",
    "    \n",
    "    '''Class used to derive peaks information, musical scales and related metrics from time series  \n",
    "    \n",
    "    Example of use:       \n",
    "    biotuning = biotuner(sf = 1000)\n",
    "    biotuning.peaks_extraction(data)\n",
    "    biotuning.peaks_extension()\n",
    "    biotuning.peaks_metrics()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, sf, peaks_function = 'EEMD', precision = 0.2, compute_sub_ratios = False, \n",
    "                 n_harm = 10, harm_function = 'mult', extension_method = 'consonant_harmonic_fit'):\n",
    "        '''Initializing sampling frequency'''\n",
    "        self.sf = sf\n",
    "        '''Initializing arguments for peak extraction\n",
    "           peaks_function: method used to extract the peaks ['EEMD', 'EMD', 'HH1D_max', 'adapt', 'fixed']\n",
    "           precision: precision of the peaks in Hz\n",
    "           compute_sub_ratios: when set to True, include ratios < 1 in peaks_ratios attribute [True, False]'''\n",
    "        self.peaks_function = peaks_function\n",
    "        self.precision = precision\n",
    "        self.compute_sub_ratios = compute_sub_ratios\n",
    "        '''Initializing arguments for peaks metrics\n",
    "           n_harm: number of harmonics to compute in harmonic_fit function\n",
    "           harm_function: compute harmonics from iterative multiplication (x, 2x, 3x, ...nx) or division (x, x/2, x/3, ...x/n) ['mult', 'div']\n",
    "           extension_method: ['harmonic_fit', 'consonant', 'multi_consonant', 'consonant_harmonic_fit', 'multi_consonant_harmonic_fit']'''\n",
    "        self.n_harm = n_harm\n",
    "        self.harm_function = harm_function\n",
    "        self.extension_method = extension_method\n",
    "        '''Initializing dictionary for scales metrics'''\n",
    "        self.scale_metrics = {}\n",
    "    \n",
    "    \n",
    "    '''First method to use. Requires data as input argument\n",
    "       Generates self.peaks and self.peaks_ratios attributes'''\n",
    "\n",
    "    def peaks_extraction (self, data, peaks_function = None, FREQ_BANDS = None, precision = None, sf = None, max_freq = 80, compute_sub_ratios = None):\n",
    "        self.data = data\n",
    "        if sf == None:\n",
    "            sf = self.sf\n",
    "        if precision == None:\n",
    "            precision = self.precision\n",
    "        if peaks_function == None:\n",
    "            peaks_function = self.peaks_function\n",
    "        if compute_sub_ratios == None:\n",
    "            compute_sub_ratios = self.compute_sub_ratios\n",
    "        self.peaks, self.amps = self.compute_peaks_ts (data, peaks_function = peaks_function, FREQ_BANDS = None, precision = precision, sf = sf, max_freq = max_freq)\n",
    "\n",
    "        self.peaks_ratios = compute_peak_ratios(self.peaks, rebound = True, octave = 2, sub = compute_sub_ratios)\n",
    "        \n",
    "    '''Generates self.extended_peaks and self.extended_peaks_ratios attributes'''\n",
    "    \n",
    "    def peaks_extension (self, peaks = None, n_harm = None, method = None, harm_function = 'mult', cons_limit = 0.1):\n",
    "        if peaks == None:\n",
    "            peaks = self.peaks\n",
    "        if n_harm == None:\n",
    "            n_harm = self.n_harm\n",
    "        if method == None:\n",
    "            method = self.extension_method\n",
    "        if method == 'harmonic_fit':\n",
    "            extended_peaks = harmonic_fit(peaks, self.n_harm, function = harm_function, div_mode = 'div')\n",
    "            self.extended_peaks = np.sort(list(self.peaks)+list(extended_peaks))\n",
    "        if method == 'consonant':\n",
    "            consonance, cons_pairs, cons_peaks, cons_metric = consonance_peaks (peaks, limit = cons_limit)\n",
    "            self.extended_peaks = np.sort(np.round(cons_peaks, 3))\n",
    "        if method == 'multi_consonant':\n",
    "            consonance, cons_pairs, cons_peaks, cons_metric = consonance_peaks (peaks, limit = cons_limit)\n",
    "            self.extended_peaks = np.sort(np.round(multi_consonance(cons_pairs, n_freqs = 10), 3))\n",
    "        if method == 'consonant_harmonic_fit':\n",
    "            extended_peaks = harmonic_fit(peaks, self.n_harm, function = harm_function, div_mode = 'div_add')\n",
    "            consonance, cons_pairs, cons_peaks, cons_metric = consonance_peaks (extended_peaks, limit = cons_limit)\n",
    "            self.extended_peaks = np.sort(np.round(cons_peaks, 3))\n",
    "        if method == 'multi_consonant_harmonic_fit':\n",
    "            extended_peaks = harmonic_fit(peaks, self.n_harm, function = harm_function)\n",
    "            consonance, cons_pairs, cons_peaks, cons_metric = consonance_peaks (extended_peaks, limit = cons_limit)\n",
    "            self.extended_peaks = np.sort(np.round(multi_consonance(cons_pairs, n_freqs = 10), 3))\n",
    "        self.extended_peaks = [i for i in self.extended_peaks if i<self.sf/2]\n",
    "        self.extended_amps = peaks_to_amps(self.extended_peaks, self.freqs, self.psd, self.sf)\n",
    "        self.extended_peaks_ratios = compute_peak_ratios(self.extended_peaks)\n",
    "        \n",
    "    \n",
    "    def compute_spectromorph (self, IMFs = None, sf = None, method = 'SpectralCentroid', window = None, overlap = 1, comp_chords = False, min_notes = 3, limit = 0.2, cons_chord_method = 'cons'):\n",
    "        if IMFs == None:\n",
    "            try:\n",
    "                IMFs = self.IMFs\n",
    "            except:\n",
    "                IMFs = EMD_eeg(self.data)[1:6]\n",
    "                self.IMFs = IMFs\n",
    "                \n",
    "        if sf == None:\n",
    "            sf = self.sf\n",
    "        if window == None:\n",
    "            window = int(sf/2)\n",
    "            \n",
    "        spectro_EMD = EMD_to_spectromorph(IMFs, 1000, method = method, window = window, overlap = overlap)\n",
    "        self.spectro_EMD = np.round(spectro_EMD, 1)\n",
    "        if method == 'SpectralCentroid':\n",
    "            self.SpectralCentroid = self.spectro_EMD\n",
    "        if method == 'SpectralFlux':\n",
    "            self.SpectralFlux = self.spectro_EMD\n",
    "        if comp_chords == True:\n",
    "            self.spectro_chords = timepoint_consonance(self.spectro_EMD, method = cons_chord_method, limit = limit, min_notes = min_notes)  \n",
    "            \n",
    "    def compute_peaks_metrics (self, n_harm = None):\n",
    "        if n_harm == None:\n",
    "            n_harm = self.n_harm\n",
    "            \n",
    "        peaks = list(self.peaks)\n",
    "        metrics = {'cons' : 0, 'euler' : 0, 'tenney': 0, 'harm_fit': 0}   \n",
    "        metrics['harm_fit'] = len(harmonic_fit(peaks, n_harm = n_harm))\n",
    "        a, b, c, metrics['cons'] = consonance_peaks (peaks, 0.1)\n",
    "        peaks_euler = [int(round(num, 2)*1000) for num in peaks]\n",
    "        metrics['euler'] = euler(*peaks_euler)\n",
    "        metrics['tenney'] = tenneyHeight(peaks)\n",
    "        metrics_list = []\n",
    "        for value in metrics.values():\n",
    "            metrics_list.append(value)\n",
    "        self.peaks_metrics_list = metrics_list\n",
    "        self.peaks_metrics = metrics\n",
    "\n",
    "    '''Methods to compute scales from whether peaks or extended peaks'''\n",
    "    \n",
    "    def compute_diss_curve (self, input_type = 'peaks', denom=1000, max_ratio=2, consonance = True, method = 'min', plot = False, n_tet_grid = 12):\n",
    "        if input_type == 'peaks':\n",
    "            peaks = self.peaks\n",
    "            amps = self.amps\n",
    "        if input_type == 'extended_peaks':\n",
    "            peaks = self.extended_peaks\n",
    "            amps = self.extended_amps\n",
    "\n",
    "        peaks = [p*128 for p in peaks]\n",
    "        amps = np.interp(amps, (np.array(amps).min(), np.array(amps).max()), (0.2, 0.8))\n",
    "        \n",
    "        intervals, self.diss_scale, euler_diss, diss, harm_sim_diss = diss_curve (peaks, amps, denom=denom, max_ratio=max_ratio, consonance = consonance, method = method, plot = plot, n_tet_grid = n_tet_grid)\n",
    "        self.scale_metrics['diss_euler'] = euler_diss\n",
    "        self.scale_metrics['dissonance'] = diss\n",
    "        self.scale_metrics['diss_harm_sim'] = np.average(harm_sim_diss)\n",
    "        self.scale_metrics['diss_n_steps'] = len(self.diss_scale)\n",
    "        \n",
    "    def compute_harmonic_entropy(self, input_type = 'peaks', res = 0.001, spread = 0.01, plot_entropy = True, plot_tenney = False):\n",
    "        if input_type == 'peaks':\n",
    "            ratios = self.peaks_ratios\n",
    "        if input_type == 'extended_peaks':\n",
    "            ratios = self.extended_peaks_ratios\n",
    "            #print(ratios)\n",
    "        HE_scale, HE = harmonic_entropy(ratios, res = res, spread = spread, plot_entropy = plot_entropy, plot_tenney = plot_tenney)\n",
    "        self.HE_scale = HE_scale[0]\n",
    "        self.scale_metrics['HE'] = HE\n",
    "        self.scale_metrics['HE_n_steps'] = len(self.HE_scale)  \n",
    "        self.scale_metrics['HE_harm_sim'] = np.average(ratios2harmsim(list(biotuning.HE_scale)))\n",
    "        '''\n",
    "        ratios_euler = [a]+ratios\n",
    "        ratios_euler = [int(round(num, 2)*1000) for num in ratios]\n",
    "        euler_score = None\n",
    "        if consonance == True:\n",
    "            euler_score = euler(*ratios_euler)\n",
    "            euler_score = euler_score/len(diss_minima)\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Methods called by the peaks_extraction method'''\n",
    "    \n",
    "    def compute_peak(self, eeg_data, sf=1000, nperseg = 0, nfft = 0, precision = 0.25, average = 'median'):\n",
    "        if nperseg == 0:\n",
    "            mult = 1/precision\n",
    "            nperseg = sf*mult\n",
    "            nfft = nperseg\n",
    "        import scipy\n",
    "        freqs, psd = scipy.signal.welch(eeg_data, sf, nfft = nfft, nperseg = nperseg, average = average)\n",
    "        self.freqs = freqs\n",
    "        self.psd = psd\n",
    "        psd = 10. * np.log10(psd) \n",
    "        bin_size = (sf/2)/len(freqs)\n",
    "        #min_index = int(minf/bin_size)\n",
    "        #max_index = int(maxf/bin_size)\n",
    "        index_max = np.argmax(np.array(psd))\n",
    "        FREQS = np.array(freqs[index_max])\n",
    "        amps = np.array(psd[index_max])\n",
    "\n",
    "        return FREQS, amps\n",
    "    \n",
    "    def compute_peaks_raw(self, eeg_data, FREQ_BANDS, sf=1000, nperseg = 0, nfft = 0, precision=0.25, average = 'median'):\n",
    "        if nperseg == 0:\n",
    "            mult = 1/precision\n",
    "            nperseg = sf*mult\n",
    "            nfft = nperseg\n",
    "        import scipy\n",
    "        psd_all = []\n",
    "        freqs_all = []\n",
    "        FREQs_temp= []\n",
    "        amp_temp = []\n",
    "\n",
    "        for minf, maxf in FREQ_BANDS:\n",
    "            freqs, psd = scipy.signal.welch(eeg_data, sf, nfft = nfft, nperseg = nperseg, average = average)\n",
    "            self.freqs = freqs\n",
    "            psd = 10. * np.log10(psd)\n",
    "            self.psd = psd\n",
    "            bin_size = (sf/2)/len(freqs)\n",
    "            self.bin_size = bin_size\n",
    "            min_index = int(minf/bin_size)\n",
    "            max_index = int(maxf/bin_size)\n",
    "            index_max = np.argmax(np.array(psd[min_index:max_index]))\n",
    "             #   print(index_max) # Should not be zero in all bands (would signify strong 1/f trend)\n",
    "            FREQs_temp.append(freqs[min_index+index_max])\n",
    "            amp_temp.append(psd[min_index+index_max])\n",
    "\n",
    "        FREQS = np.array(FREQs_temp)\n",
    "        amps = np.array(amp_temp)\n",
    "        return FREQS, amps\n",
    "    \n",
    "    def compute_peaks_ts (self, data, peaks_function = 'EMD', FREQ_BANDS = None, precision = 0.25, sf = 1000, max_freq = 80):\n",
    "        alphaband = [[7, 12]]\n",
    "        try:\n",
    "            if FREQ_BANDS == None:\n",
    "                FREQ_BANDS = [[2, 3.55], [3.55, 7.15], [7.15, 14.3], [14.3, 28.55], [28.55, 49.4]]\n",
    "        except:\n",
    "            pass\n",
    "        if peaks_function == 'EEMD':\n",
    "            IMFs = EMD_eeg(data)[1:6]\n",
    "            self.IMFs = IMFs\n",
    "        if peaks_function == 'EMD':\n",
    "            data = np.interp(data, (data.min(), data.max()), (0, +1))\n",
    "            IMFs = emd.sift.sift(data)\n",
    "            #IMFs = emd.sift.ensemble_sift(data)\n",
    "            IMFs = np.moveaxis(IMFs, 0, 1)[1:6]\n",
    "            self.IMFs = IMFs\n",
    "        try:\n",
    "            peaks_temp = []\n",
    "            amps_temp = []\n",
    "            for imf in range(len(IMFs)):\n",
    "                p, a = self.compute_peak(IMFs[imf], precision = precision, average = 'median')\n",
    "                peaks_temp.append(p)\n",
    "\n",
    "                amps_temp.append(a)\n",
    "\n",
    "            peaks_temp = np.flip(peaks_temp)\n",
    "            amps_temp = np.flip(amps_temp)\n",
    "        except:\n",
    "            pass\n",
    "        if peaks_function == 'HH1D_max':\n",
    "            IMFs = EMD_eeg(data)\n",
    "            IMFs = np.moveaxis(IMFs, 0, 1)\n",
    "            IP, IF, IA = emd.spectra.frequency_transform(IMFs[:, 1:6], sf, 'nht')\n",
    "            precision_hh = precision*2\n",
    "            low = 1\n",
    "            high = max_freq\n",
    "            steps = int((high-low)/precision_hh)\n",
    "            edges, bins = emd.spectra.define_hist_bins(low, high, steps, 'log')\n",
    "\n",
    "            # Compute the 1d Hilbert-Huang transform (power over carrier frequency)\n",
    "            spec = emd.spectra.hilberthuang_1d(IF, IA, edges)\n",
    "            spec = np.moveaxis(spec, 0, 1)\n",
    "            peaks_temp = []\n",
    "            amps_temp = []\n",
    "            for e, i in enumerate(spec):\n",
    "                max_power = np.argmax(i)\n",
    "                peaks_temp.append(bins[max_power])\n",
    "                amps_temp.append(spec[e][max_power])\n",
    "            peaks_temp = np.flip(peaks_temp)\n",
    "            amps_temp = np.flip(amps_temp)\n",
    "        #if peaks_function == 'HH1D_weightAVG':\n",
    "\n",
    "        if peaks_function == 'adapt':\n",
    "            p, a = self.compute_peaks_raw(data, alphaband, precision = precision, average = 'median')\n",
    "            FREQ_BANDS = alpha2bands(p)\n",
    "            peaks_temp, amps_temp = self.compute_peaks_raw(data, FREQ_BANDS, precision = precision, average = 'median')\n",
    "        if peaks_function == 'fixed':\n",
    "            peaks_temp, amps_temp = self.compute_peaks_raw(data, FREQ_BANDS, precision = precision, average = 'median')\n",
    "        peaks = np.array(peaks_temp)\n",
    "        amps = np.array(amps_temp)\n",
    "        return peaks, amps\n",
    "    \n",
    "    \n",
    "    '''Generic method to fit all Biotuner methods'''\n",
    "    \n",
    "    def fit_all(self, data, compute_diss = True, compute_HE = True, compute_peaks_extension = True):\n",
    "        biotuning = biotuner(self.sf, peaks_function = self.peaks_function, precision = self.precision, n_harm = self.n_harm)\n",
    "        biotuning.peaks_extraction(data)\n",
    "        biotuning.compute_peaks_metrics()\n",
    "        if compute_diss == True:\n",
    "            biotuning.compute_diss_curve(input_type = 'peaks', plot = False)\n",
    "        if compute_peaks_extension == True:\n",
    "            biotuning.peaks_extension(method = 'multi_consonant_harmonic_fit', harm_function = 'mult', cons_limit = 0.01)\n",
    "        if compute_HE == True:\n",
    "            biotuning.compute_harmonic_entropy(input_type = 'extended_peaks', plot_entropy = False)\n",
    "        return biotuning\n",
    "    \n",
    "    def info(self, metrics=False, scales=False, whatever=False):\n",
    "        if metrics == True:\n",
    "            print('METRICS')\n",
    "            print(vars(self))\n",
    "        \n",
    "        else:\n",
    "            print(vars(self))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro_IMFs = EMD_to_spectromorph(biotuning.IMFs, 1000, method = 'SpectralCentroid', window = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incut = 1\n",
    "outcut = 3\n",
    "biotuning.IMFs[0][incut:outcut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9750003814697266\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "data = epochs_data[15][75][1000:6000] # Define data (single time series)\n",
    "biotuning = biotuner(1000, peaks_function = 'EEMD', precision = 0.5, n_harm = 10) # Initialize biotuner object\n",
    "biotuning.peaks_extraction(data)\n",
    "biotuning.compute_peaks_metrics()\n",
    "biotuning.peaks_extension(method = 'consonant_harmonic_fit', harm_function = 'mult', cons_limit = 0.1)\n",
    "biotuning.compute_diss_curve(plot = False, input_type = 'peaks', denom = 50, consonance = False, n_tet_grid = 12)\n",
    "biotuning.compute_spectromorph(comp_chords = True, min_notes = 5, limit = 30, cons_chord_method = 'euler')\n",
    "\n",
    "biotuning.compute_harmonic_entropy(input_type = 'extended_peaks', plot_entropy = False)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[56.7, 19.2, 7.0, 3.0, 1.0],\n",
       " [46.8, 20.0, 7.2, 2.0, 2.0],\n",
       " [48.0, 22.4, 7.0, 3.2, 3.3]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biotuning.spectro_chords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(biotuning.SpectralFlux[0][1000:2000])\n",
    "plt.plot(biotuning.SpectralFlux[1][1000:2000])\n",
    "plt.plot(biotuning.SpectralFlux[2][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in biotuning.spectro_chords:\n",
    "    i = [int(j*10) for j in i]\n",
    "    print(euler(*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = biotuning.SpectralCentroid\n",
    "#data = np.moveaxis(data, 0, 1)\n",
    "cons_peaks = timepoint_consonance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harms = [10,50]\n",
    "data = epochs_data[47][28] # Define data (single time series)\n",
    "for i in harms:\n",
    "    biotuning = biotuner(1000, peaks_function = 'EEMD', precision = 0.1, n_harm = i)\n",
    "    biotuning.peaks_extraction(data)\n",
    "    biotuning.peaks_extension(method = 'consonant_harmonic_fit', harm_function = 'mult', cons_limit = 0.1)\n",
    "    biotuning.compute_harmonic_entropy(input_type = 'extended_peaks', plot_entropy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biotuning.extended_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = oct_subdiv(3/2,0.01367,2,10)\n",
    "m = compare_oct_div(Octdiv = 53, Octdiv2 = 12, bounds = 0.003, octave = 2)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a, b = multi_oct_subdiv (biotuning.peaks, 200, 0.01)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_oct_subdiv (peaks, max_sub, octave_limit, octave = 2, n_scales = 10):\n",
    "    import itertools\n",
    "    from collections import Counter\n",
    "    a, b, pairs, cons = consonance_peaks(peaks, 0.01)\n",
    "    ratios, cons = consonant_ratios(peaks, 0.01)\n",
    "    print(ratios)\n",
    "    list_oct_div = []\n",
    "    for i in range(len(ratios)):\n",
    "        list_temp, no= oct_subdiv(ratios[i], octave_limit, octave, n_scales)\n",
    "        print(list_temp)\n",
    "        list_oct_div.append(list_temp)\n",
    "\n",
    "\n",
    "    counts = Counter(list(itertools.chain(*list_oct_div)))\n",
    "    oct_div_temp = []\n",
    "    for k, v in counts.items():\n",
    "        if v > 1:\n",
    "            oct_div_temp.append(k)\n",
    "    oct_div_temp = np.sort(oct_div_temp)\n",
    "    oct_div_final = []\n",
    "    for i in range(len(oct_div_temp)):\n",
    "        if oct_div_temp[i] < max_sub:\n",
    "            oct_div_final.append(oct_div_temp[i])\n",
    "    return oct_div_final, ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biotuning.HE_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biotuning = biotuner(1000, peaks_function = 'adapt', precision = 0.1, n_harm = 30)\n",
    "biotuning = biotuning.fit_all(data)\n",
    "biotuning.peaks_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sf': 1000,\n",
       " 'peaks_function': 'EEMD',\n",
       " 'precision': 0.5,\n",
       " 'compute_sub_ratios': False,\n",
       " 'n_harm': 10,\n",
       " 'harm_function': 'mult',\n",
       " 'extension_method': 'consonant_harmonic_fit',\n",
       " 'scale_metrics': {'diss_euler': 'NaN',\n",
       "  'dissonance': 0.6992125517857091,\n",
       "  'diss_harm_sim': 5.0488551814855915,\n",
       "  'diss_n_steps': 5,\n",
       "  'HE': 0.13748377419307395,\n",
       "  'HE_n_steps': 2,\n",
       "  'HE_harm_sim': 0.3186412770044671},\n",
       " 'data': array([-6.44106583e-06, -7.66116008e-06, -6.63545513e-06, ...,\n",
       "         4.94809784e-06,  5.46680818e-06,  7.47553968e-06]),\n",
       " 'IMFs': array([[-0.05592517, -0.05768303, -0.04785895, ..., -0.01050714,\n",
       "          0.01071207,  0.02154948],\n",
       "        [-0.05550147, -0.05283399, -0.04960932, ...,  0.01453617,\n",
       "          0.01341331,  0.01202148],\n",
       "        [ 0.0381894 ,  0.03769644,  0.03703878, ...,  0.12126636,\n",
       "          0.12181089,  0.1217459 ],\n",
       "        [-0.00819349, -0.01046172, -0.01270604, ...,  0.07454534,\n",
       "          0.07400433,  0.07347042],\n",
       "        [-0.02568414, -0.02581378, -0.02593423, ..., -0.05763544,\n",
       "         -0.05732151, -0.05700454]]),\n",
       " 'freqs': array([  0. ,   0.5,   1. , ..., 499. , 499.5, 500. ]),\n",
       " 'psd': array([2.81961179e-05, 1.57363308e-05, 1.65809405e-06, ...,\n",
       "        2.40021169e-22, 5.00369631e-22, 4.67532576e-22]),\n",
       " 'peaks': array([ 3. ,  5. ,  8.5, 27.5, 49.5]),\n",
       " 'amps': array([-33.88278712, -29.2543599 , -27.48201507, -35.12366967,\n",
       "        -40.82328429]),\n",
       " 'peaks_ratios': [1.03125,\n",
       "  1.1458333333333333,\n",
       "  1.2375,\n",
       "  1.375,\n",
       "  1.4166666666666667,\n",
       "  1.4558823529411764,\n",
       "  1.6176470588235294,\n",
       "  1.6666666666666667,\n",
       "  1.7,\n",
       "  1.8],\n",
       " 'peaks_metrics_list': [0.13193116830065357, 36, 7.288763465336087, 8],\n",
       " 'peaks_metrics': {'cons': 0.13193116830065357,\n",
       "  'euler': 36,\n",
       "  'tenney': 7.288763465336087,\n",
       "  'harm_fit': 8},\n",
       " 'extended_peaks': [8.75, 15.0, 30.0, 55.0, 247.5],\n",
       " 'extended_amps': [4.784386880840595e-08,\n",
       "  6.177210405742166e-11,\n",
       "  7.85340810838712e-13,\n",
       "  1.2108029373227662e-14,\n",
       "  6.755889231437022e-20],\n",
       " 'extended_peaks_ratios': [1.03125,\n",
       "  1.125,\n",
       "  1.5714285714285714,\n",
       "  1.7142857142857142,\n",
       "  1.7678571428571428,\n",
       "  1.8333333333333333],\n",
       " 'diss_scale': [1.325, 1.6666666666666667, 1.7, 1.8, 2.0],\n",
       " 'spectro_EMD': array([[58.6, 58.6, 58.6, ..., 48.9, 48.9, 48.9],\n",
       "        [28.3, 28.3, 28.4, ..., 23. , 23. , 22.9],\n",
       "        [12.1, 12.2, 12.2, ..., 10.1, 10.1, 10.1],\n",
       "        [ 3.5,  3.4,  3.4, ...,  5.5,  5.5,  5.4],\n",
       "        [ 1.1,  1.1,  1.1, ...,  2.6,  2.6,  2.6]]),\n",
       " 'SpectralCentroid': array([[58.6, 58.6, 58.6, ..., 48.9, 48.9, 48.9],\n",
       "        [28.3, 28.3, 28.4, ..., 23. , 23. , 22.9],\n",
       "        [12.1, 12.2, 12.2, ..., 10.1, 10.1, 10.1],\n",
       "        [ 3.5,  3.4,  3.4, ...,  5.5,  5.5,  5.4],\n",
       "        [ 1.1,  1.1,  1.1, ...,  2.6,  2.6,  2.6]]),\n",
       " 'spectro_chords': [[57.6, 30.0, 15.6, 3.6, 1.2],\n",
       "  [56.1, 30.0, 13.2, 4.5, 1.6],\n",
       "  [54.0, 29.7, 9.5, 3.8, 2.1],\n",
       "  [61.6, 28.8, 9.6, 5.6, 2.4],\n",
       "  [62.0, 28.8, 9.6, 5.6, 2.4],\n",
       "  [59.4, 19.6, 11.2, 4.9, 3.6],\n",
       "  [56.7, 16.8, 11.0, 5.0, 3.9],\n",
       "  [54.0, 18.0, 13.6, 6.3, 4.2],\n",
       "  [63.0, 28.0, 14.0, 7.7, 3.3],\n",
       "  [56.7, 23.0, 11.5, 5.0, 3.5],\n",
       "  [56.7, 23.8, 10.0, 5.0, 3.4],\n",
       "  [32.0, 16.2, 9.5, 5.6, 2.5],\n",
       "  [32.0, 16.2, 9.6, 5.6, 2.5],\n",
       "  [32.4, 16.5, 9.9, 5.7, 2.5],\n",
       "  [34.0, 17.5, 10.4, 6.0, 2.6],\n",
       "  [34.0, 17.5, 10.5, 6.0, 2.6],\n",
       "  [44.0, 21.6, 11.9, 6.3, 3.2],\n",
       "  [52.5, 22.0, 12.5, 6.3, 3.0],\n",
       "  [63.0, 20.8, 13.0, 6.0, 2.6],\n",
       "  [56.1, 24.5, 9.8, 6.0, 3.0],\n",
       "  [52.5, 27.0, 8.1, 5.2, 3.9],\n",
       "  [53.2, 22.0, 8.8, 5.6, 2.2],\n",
       "  [52.8, 22.0, 8.8, 5.7, 2.1],\n",
       "  [50.0, 21.6, 8.5, 5.6, 2.0],\n",
       "  [48.6, 23.4, 9.1, 5.6, 2.2]],\n",
       " 'HE_scale': array([1.691, 1.771])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(biotuning)\n",
    "#biotuning.HE_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
